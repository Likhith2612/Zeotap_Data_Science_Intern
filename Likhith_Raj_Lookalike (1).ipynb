{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "customers_df = pd.read_csv('/content/Updated_Customers.csv')\n",
        "products_df = pd.read_csv('/content/Products - Products.csv')\n",
        "transactions_df = pd.read_csv('/content/Transactions - Transactions.csv')\n",
        "\n",
        "customer_transactions_df = pd.merge(transactions_df, customers_df, on='CustomerID', how='left')\n",
        "\n",
        "full_data_df = pd.merge(customer_transactions_df, products_df, on='ProductID', how='left')\n",
        "\n",
        "full_data_df['TransactionDate'] = pd.to_datetime(full_data_df['TransactionDate'], errors='coerce')\n",
        "print(\"Missing Values Before Cleaning:\")\n",
        "print(full_data_df.isnull().sum())\n",
        "\n",
        "full_data_df.drop(columns=['Price_x'], inplace=True)\n",
        "full_data_df.rename(columns={'Price_y': 'Price'}, inplace=True)\n",
        "\n",
        "full_data_df.dropna(inplace=True)\n",
        "\n",
        "full_data_df['Price'] = pd.to_numeric(full_data_df['Price'], errors='coerce')\n",
        "full_data_df['Quantity'] = pd.to_numeric(full_data_df['Quantity'], errors='coerce')\n",
        "full_data_df['TotalValue'] = pd.to_numeric(full_data_df['TotalValue'], errors='coerce')\n",
        "\n",
        "print(\"Data Types After Cleaning:\")\n",
        "print(full_data_df.dtypes)\n",
        "print(\"Missing Values After Cleaning:\")\n",
        "print(full_data_df.isnull().sum())\n",
        "full_data_df.to_csv('Cleaned_Merged_Customer_Product_Transactions.csv', index=False)\n",
        "\n",
        "print(\"Cleaned Data Sample:\")\n",
        "print(full_data_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNzjKrL3sh1Q",
        "outputId": "b07cdd1c-a2f7-43c4-e93f-5b053d16c463"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values Before Cleaning:\n",
            "TransactionID      0\n",
            "CustomerID         0\n",
            "ProductID          0\n",
            "TransactionDate    0\n",
            "Quantity           0\n",
            "TotalValue         0\n",
            "Price_x            0\n",
            "CustomerName       0\n",
            "Region             0\n",
            "SignupDate         0\n",
            "ProductName        0\n",
            "Category           0\n",
            "Price_y            0\n",
            "dtype: int64\n",
            "Data Types After Cleaning:\n",
            "TransactionID              object\n",
            "CustomerID                 object\n",
            "ProductID                  object\n",
            "TransactionDate    datetime64[ns]\n",
            "Quantity                    int64\n",
            "TotalValue                float64\n",
            "CustomerName               object\n",
            "Region                     object\n",
            "SignupDate                 object\n",
            "ProductName                object\n",
            "Category                   object\n",
            "Price                     float64\n",
            "dtype: object\n",
            "Missing Values After Cleaning:\n",
            "TransactionID        0\n",
            "CustomerID           0\n",
            "ProductID            0\n",
            "TransactionDate      0\n",
            "Quantity             0\n",
            "TotalValue         257\n",
            "CustomerName         0\n",
            "Region               0\n",
            "SignupDate           0\n",
            "ProductName          0\n",
            "Category             0\n",
            "Price                0\n",
            "dtype: int64\n",
            "Cleaned Data Sample:\n",
            "  TransactionID CustomerID ProductID     TransactionDate  Quantity  \\\n",
            "0        T00001      C0199      P067 2024-08-25 12:38:23         1   \n",
            "1        T00112      C0146      P067 2024-05-27 22:23:54         1   \n",
            "2        T00166      C0127      P067 2024-04-25 07:38:55         1   \n",
            "3        T00272      C0087      P067 2024-03-26 22:55:37         2   \n",
            "4        T00363      C0070      P067 2024-03-21 15:10:10         3   \n",
            "\n",
            "   TotalValue     CustomerName         Region  SignupDate  \\\n",
            "0      300.68   Andrea Jenkins         Europe  03/12/2022   \n",
            "1      300.68  Brittany Harvey           Asia  04/09/2024   \n",
            "2      300.68  Kathryn Stevens         Europe  04/04/2024   \n",
            "3      601.36  Travis Campbell  South America  11/04/2024   \n",
            "4      902.04    Timothy Perez         Europe  15/03/2022   \n",
            "\n",
            "                       ProductName     Category   Price  \n",
            "0  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
            "1  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
            "2  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
            "3  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
            "4  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-a82f1380c8f0>:16: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  full_data_df['TransactionDate'] = pd.to_datetime(full_data_df['TransactionDate'], errors='coerce')  # Coerce errors to NaT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "full_data_df = pd.read_csv('/content/Cleaned_Merged_Customer_Product_Transactions.csv')\n",
        "\n",
        "print(full_data_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjzDs7BCukvX",
        "outputId": "833c3935-f671-4ae4-d480-7b6f44459e78"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
            "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
            "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
            "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
            "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
            "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
            "\n",
            "   TotalValue     CustomerName         Region  SignupDate  \\\n",
            "0      300.68   Andrea Jenkins         Europe  03/12/2022   \n",
            "1      300.68  Brittany Harvey           Asia  04/09/2024   \n",
            "2      300.68  Kathryn Stevens         Europe  04/04/2024   \n",
            "3      601.36  Travis Campbell  South America  11/04/2024   \n",
            "4      902.04    Timothy Perez         Europe  15/03/2022   \n",
            "\n",
            "                       ProductName     Category   Price  \n",
            "0  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
            "1  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
            "2  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
            "3  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n",
            "4  ComfortLiving Bluetooth Speaker  Electronics  300.68  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"For Predication \"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "full_data_df = pd.read_csv('/content/Cleaned_Merged_Customer_Product_Transactions.csv')\n",
        "\n",
        "customer_features = full_data_df.groupby('CustomerID').agg({\n",
        "    'Region': 'first',\n",
        "    'SignupDate': 'first',\n",
        "    'Quantity': 'sum',\n",
        "    'TotalValue': 'sum',\n",
        "    'Price': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "customer_features = pd.get_dummies(customer_features, columns=['Region'], drop_first=True)\n",
        "scaler = StandardScaler()\n",
        "numeric_cols = ['Quantity', 'TotalValue', 'Price']\n",
        "customer_features[numeric_cols] = scaler.fit_transform(customer_features[numeric_cols])\n",
        "\n",
        "similarity_matrix = cosine_similarity(customer_features[numeric_cols + list(customer_features.columns[2:])])\n",
        "\n",
        "def get_top_3_lookalikes(customer_id, customer_features, similarity_matrix):\n",
        "    customer_index = customer_features[customer_features['CustomerID'] == customer_id].index[0]\n",
        "    similarities = similarity_matrix[customer_index]\n",
        "    similar_customers = np.argsort(similarities)[::-1][1:4]\n",
        "    similar_customer_ids = customer_features['CustomerID'].iloc[similar_customers].values\n",
        "    scores = similarities[similar_customers]\n",
        "    return list(zip(similar_customer_ids, scores))\n",
        "\n",
        "customer_id_input = input(\"Enter CustomerID (e.g., C0001): \")\n",
        "top_3_lookalikes = get_top_3_lookalikes(customer_id_input, customer_features, similarity_matrix)\n",
        "\n",
        "print(f\"Top 3 Lookalikes for Customer {customer_id_input}:\")\n",
        "for i, (lookalike, score) in enumerate(top_3_lookalikes, 1):\n",
        "    print(f\"Lookalike {i}: {lookalike}, Similarity Score: {score}\")\n",
        "\n",
        "actual_lookalikes = [\n",
        "    ('C0076', 0.9446), ('C0011', 0.9432), ('C0137', 0.9298)\n",
        "]\n",
        "\n",
        "def calculate_mse(actual_lookalikes, predicted_lookalikes):\n",
        "    actual_scores = [score for _, score in actual_lookalikes]\n",
        "    predicted_scores = [score for _, score in predicted_lookalikes]\n",
        "\n",
        "    mse = mean_squared_error(actual_scores, predicted_scores)\n",
        "    return mse\n",
        "\n",
        "mse = calculate_mse(actual_lookalikes, top_3_lookalikes)\n",
        "print(f\"Mean Squared Error (MSE) between actual and predicted lookalikes: {mse}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUjpKh4ny695",
        "outputId": "56e7f0c6-4357-4e91-ff63-a92a517c3619"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter CustomerID (e.g., C0001): C0199\n",
            "Top 3 Lookalikes for Customer C0199:\n",
            "Lookalike 1: C0073, Similarity Score: 0.9850059276267502\n",
            "Lookalike 2: C0132, Similarity Score: 0.974943257219227\n",
            "Lookalike 3: C0019, Similarity Score: 0.9196573480364263\n",
            "Mean Squared Error (MSE) between actual and predicted lookalikes: 0.0009143822517061226\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" For Look a like csv\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "full_data_df = pd.read_csv('/content/Cleaned_Merged_Customer_Product_Transactions.csv')\n",
        "customer_features = full_data_df.groupby('CustomerID').agg({\n",
        "    'Region': 'first',\n",
        "    'SignupDate': 'first',\n",
        "    'Quantity': 'sum',\n",
        "    'TotalValue': 'sum',\n",
        "    'Price': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "customer_features = pd.get_dummies(customer_features, columns=['Region'], drop_first=True)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "numeric_cols = ['Quantity', 'TotalValue', 'Price']\n",
        "customer_features[numeric_cols] = scaler.fit_transform(customer_features[numeric_cols])\n",
        "\n",
        "similarity_matrix = cosine_similarity(customer_features[numeric_cols + list(customer_features.columns[2:])])\n",
        "\n",
        "top_3_lookalikes = {}\n",
        "\n",
        "for i, customer_id in enumerate(customer_features['CustomerID'].head(20)):\n",
        "    similarities = similarity_matrix[i]\n",
        "    similar_customers = np.argsort(similarities)[::-1][1:4]\n",
        "    similar_customer_ids = customer_features['CustomerID'].iloc[similar_customers].values\n",
        "    scores = similarities[similar_customers]\n",
        "    top_3_lookalikes[customer_id] = list(zip(similar_customer_ids, scores))\n",
        "\n",
        "\n",
        "lookalike_data = []\n",
        "\n",
        "for customer_id, lookalikes in top_3_lookalikes.items():\n",
        "    lookalike_data.append([customer_id] + [f\"{lookalike[0]}:{lookalike[1]:.4f}\" for lookalike in lookalikes])\n",
        "lookalike_df = pd.DataFrame(lookalike_data, columns=['CustomerID', 'Lookalike_1', 'Lookalike_2', 'Lookalike_3'])\n",
        "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
        "\n",
        "print(\"Top 3 Lookalikes for First 20 Customers:\")\n",
        "print(lookalike_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C6cyRVmzA49",
        "outputId": "71a7fc51-7968-4e90-bd36-5e6b6aee66c0"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Lookalikes for First 20 Customers:\n",
            "  CustomerID   Lookalike_1   Lookalike_2   Lookalike_3\n",
            "0      C0001  C0076:0.9446  C0011:0.9432  C0137:0.9298\n",
            "1      C0002  C0025:0.8750  C0157:0.8581  C0121:0.8524\n",
            "2      C0003  C0190:0.9546  C0091:0.9086  C0174:0.9045\n",
            "3      C0004  C0175:0.9434  C0109:0.9369  C0101:0.9319\n",
            "4      C0005  C0186:0.9127  C0103:0.8282  C0131:0.8167\n"
          ]
        }
      ]
    }
  ]
}